{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4b5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ab619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(directory, team_name):\n",
    "    \n",
    "    out_path = f'{directory}/{team_name}'\n",
    "    try:\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "    except OSError:\n",
    "        print(f'Error: Creating directory {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047fbc4",
   "metadata": {},
   "source": [
    "#### Functions for creating team datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f04b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_dataset(link, table_id):\n",
    "    \n",
    "    # Create soup object\n",
    "    fbref_link = requests.get(link).text\n",
    "    soup = BeautifulSoup(fbref_link, 'lxml')\n",
    "\n",
    "    # Find the table with team stats\n",
    "    table = soup.find('table', id = table_id)\n",
    "    \n",
    "    # Get the column names from the first row of the table\n",
    "    cols = []\n",
    "\n",
    "    # Get date column from the row header\n",
    "    cols.append(table.tbody.tr.th.get('data-stat'))\n",
    "\n",
    "    # Get other column titles from the specific table cells\n",
    "    for cell in table.tbody.tr.find_all('td'):\n",
    "        cols.append(cell.get('data-stat'))\n",
    "\n",
    "    # Create empty dataframe with column names from created list\n",
    "    team_data = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Iterate over all the rows in the table, and add to empty dataframe\n",
    "    for row in table.tbody.find_all('tr'):\n",
    "\n",
    "        # Initialize empty dict for the team\n",
    "        team_dict = {}\n",
    "\n",
    "        # Get the match date from row header\n",
    "        team_dict['date'] = row.th.get('csk')\n",
    "\n",
    "        # Iterate over all the cells and get the remaining column values\n",
    "        for cell in row.find_all('td'):\n",
    "            stat = cell.get('data-stat')\n",
    "            value = cell.text\n",
    "            team_dict[stat] = value\n",
    "\n",
    "         # Append team-match row to dataframe        \n",
    "        team_data = team_data.append(team_dict, ignore_index=True)\n",
    "        \n",
    "    return team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6a9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_team_dataset(dataset):\n",
    "    \n",
    "    cols_to_keep = ['date', 'comp', 'round', 'dayofweek', 'venue', 'result', 'goals_for', 'goals_against', 'opponent', \n",
    "               'xg_for', 'xg_against', 'possession']\n",
    "\n",
    "    dataset = dataset[cols_to_keep]\n",
    "\n",
    "    # # Convert date to date format\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    \n",
    "    # Keep only premier league games\n",
    "    dataset = dataset[dataset['comp'].str.strip() == 'Premier League']\n",
    "\n",
    "    # Strip the round variable to only keep the number\n",
    "    dataset['round'] = dataset['round'].str.split().str[1]\n",
    "\n",
    "    # Replace empty space with missing values\n",
    "    dataset = dataset.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    # Drop rows where there is no match data\n",
    "    dataset = dataset.dropna(subset = ['result'])\n",
    "\n",
    "    # Create a list for object cols\n",
    "    object_cols = ['date', 'dayofweek', 'round', 'venue', 'result','opponent']\n",
    "    \n",
    "    # Convert round to int64\n",
    "    dataset['round'] = dataset['round'].astype('int64', errors='ignore')\n",
    "\n",
    "    # # Except objectcols all columns should be numerical\n",
    "    for col in dataset.columns:\n",
    "        if col not in object_cols:\n",
    "            dataset[col] = dataset[col].astype(float, errors='ignore')\n",
    "            \n",
    "    return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddaaf264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_team_dataset(dataset, directory, team_name):\n",
    "    \n",
    "    create_folder(directory, team_name)\n",
    "\n",
    "    dataset.to_csv(f'{directory}/{team_name}/summary_team_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252a3eb",
   "metadata": {},
   "source": [
    "#### Functions for creating squad datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3389fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_squad_dataset(link, table_id):\n",
    "    \n",
    "    fbref_link = requests.get(link).text\n",
    "    soup = BeautifulSoup(fbref_link, 'lxml')\n",
    "    \n",
    "    # Create a soup object for the all-stats table\n",
    "    table = soup.find('table', id = table_id)\n",
    "\n",
    "    # Get the column names from the first row of the table\n",
    "    cols = []\n",
    "\n",
    "    # Get player name column from the row header\n",
    "    cols.append(table.tbody.tr.th.get('data-stat'))\n",
    "\n",
    "    # Get other column titles from the specific table cells\n",
    "    for cell in table.tbody.tr.find_all('td'):\n",
    "        cols.append(cell.get('data-stat'))\n",
    "\n",
    "    # Create empty dataframe with column names from created list\n",
    "    squad_data = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    # Iterate over all the rows in the table, and add to empty dataframe\n",
    "    for row in table.tbody.find_all('tr'):\n",
    "    \n",
    "        # Initialize empty dict for the player\n",
    "        squad_dict = {}\n",
    "\n",
    "        # Get the player's name from row header\n",
    "        squad_dict['player'] = row.th.get('csk')\n",
    "\n",
    "        # Iterate over all the cells and get the remaining column values\n",
    "        for cell in row.find_all('td'):\n",
    "            stat = cell.get('data-stat')\n",
    "            if cell.get('data-stat') != 'matches':\n",
    "                value = cell.text\n",
    "                squad_dict[stat] = value\n",
    "            else:\n",
    "                link = 'https://fbref.com' + cell.a.get('href')\n",
    "                squad_dict[stat] = link\n",
    "\n",
    "         # Append player row to dataframe        \n",
    "        squad_data = squad_data.append(squad_dict, ignore_index=True)\n",
    "        \n",
    "    return squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328fa838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_squad_dataset(dataset):\n",
    "    \n",
    "    # Correct age variable\n",
    "    dataset['age'] = dataset['age'].str[0:2]\n",
    "\n",
    "    # Correct nationality variable\n",
    "    dataset['nationality'] = dataset['nationality'].str.split().str[-1]\n",
    "\n",
    "    # Replace empty space with missing values\n",
    "    dataset = dataset.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Except first 3 columns, all columns should be numerical\n",
    "    for col in dataset.columns:\n",
    "        if col not in ['player', 'nationality', 'position']:\n",
    "            dataset[col] = dataset[col].astype(float, errors='ignore')\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd7024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_squad_dataset(dataset, data_type, directory, team_name):\n",
    "    \n",
    "    create_folder(directory, team_name)\n",
    "\n",
    "    dataset.to_csv(f'{directory}/{team_name}/{data_type}_squad_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ec362",
   "metadata": {},
   "source": [
    "#### Functions for creating player datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30fa7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_dataset(link, table_id):\n",
    "    \n",
    "    # Connect to FBref page\n",
    "    fbref_link = requests.get(link).text\n",
    "    soup = BeautifulSoup(fbref_link, 'lxml')\n",
    "\n",
    "    # Create a soup object for the all-stats table\n",
    "    table = soup.find('table', id = table_id)\n",
    "\n",
    "    # Create list to get all player links\n",
    "    player_links = []\n",
    "    for row in table.tbody.find_all('tr'):\n",
    "        for cell in row.find_all('td'):\n",
    "            if cell.get('data-stat') == 'matches':\n",
    "                link = 'https://fbref.com' + cell.a.get('href')\n",
    "        player_links.append(link)\n",
    "        \n",
    "    # Get the column names of the eventual dataframe by just going to the first player link page\n",
    "    player_link = player_links[0]\n",
    "    player_page = requests.get(player_link).text\n",
    "    soup = BeautifulSoup(player_page, 'lxml')\n",
    "\n",
    "    # Get the div that contains the premier league filter\n",
    "    player_prem_div = soup.find('div', class_ = 'filter')\n",
    "\n",
    "    for filt in player_prem_div.find_all('div', class_ = ''):\n",
    "        if filt.a.text.strip() == '2021-2022 Premier League':\n",
    "            player_prem_link = 'https://fbref.com' + filt.a.get('href')\n",
    "\n",
    "    # Connect to player prem page\n",
    "    player_prem_page = requests.get(player_prem_link).text\n",
    "    soup = BeautifulSoup(player_prem_page, 'lxml')\n",
    "\n",
    "    # Create table object to parse through\n",
    "    table = soup.find('table', id = 'matchlogs_11160')\n",
    "\n",
    "    # Get the column names from the first row of the table\n",
    "    cols = []\n",
    "\n",
    "    # Append player name to column name\n",
    "    cols.append('name')\n",
    "\n",
    "    # Get match date from the row header\n",
    "    cols.append(table.tbody.tr.th.get('data-stat'))\n",
    "\n",
    "    # Get other column titles from the specific table cells\n",
    "    for row in table.tbody.find_all('tr'):\n",
    "        if row.get('class') == \"unused_sub hidden\":\n",
    "            pass\n",
    "        else:\n",
    "            for cell in row.find_all('td'):\n",
    "                if cell.get('data-stat') != 'match_report':\n",
    "                    cols.append(cell.get('data-stat'))\n",
    "\n",
    "    # Get unique list of columns while preserving order\n",
    "    variables = list(dict.fromkeys(cols))\n",
    "\n",
    "    # Create empty dataframe with column names from created list\n",
    "    player_data = pd.DataFrame(columns = variables)\n",
    "    \n",
    "    # Loop through the links in the player_links list and extract info we need \n",
    "    for link in player_links:\n",
    "\n",
    "        # First browse overall stats page \n",
    "        player_page = requests.get(link).text\n",
    "        soup = BeautifulSoup(player_page, 'lxml')\n",
    "\n",
    "        # Get the div that contains the premier league filter\n",
    "        player_prem_div = soup.find('div', class_ = 'filter')\n",
    "\n",
    "        # Loop through each filter and get the link for the filter that corresponds to the premier league\n",
    "        for filt in player_prem_div.find_all('div', class_ = ''):\n",
    "            if filt.a.text.strip() == '2021-2022 Premier League':\n",
    "                player_prem_link = 'https://fbref.com' + filt.a.get('href')\n",
    "\n",
    "        # Connect to premier league player stats page\n",
    "        player_prem_page = requests.get(player_prem_link).text\n",
    "        soup = BeautifulSoup(player_prem_page, 'lxml')\n",
    "\n",
    "        # Get player name from the player page\n",
    "        player_name = soup.find('h1', itemprop=\"name\").span.text\n",
    "\n",
    "        # Create table object to parse through player stats\n",
    "        table = soup.find('table', id = 'matchlogs_11160')\n",
    "\n",
    "        # Loop through each match stats and add to dataframe\n",
    "        for row in table.tbody.find_all('tr'):\n",
    "\n",
    "            # Initialize empty dict for the player\n",
    "            player_dict = {}\n",
    "\n",
    "            # Get the name from the previously stored variable\n",
    "            player_dict['name'] = player_name\n",
    "\n",
    "            # Get the match date from row header\n",
    "            player_dict['date'] = row.th.get('csk')\n",
    "\n",
    "            # Iterate over all the cells and get the remaining column values\n",
    "            for cell in row.find_all('td'):\n",
    "                if cell.get('data-stat') != 'match_report':\n",
    "                    stat = cell.get('data-stat')\n",
    "                    value = cell.text\n",
    "                    player_dict[stat] = value\n",
    "\n",
    "            # Append player row to dataframe        \n",
    "            player_data = player_data.append(player_dict, ignore_index=True)\n",
    "            \n",
    "    return player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23437099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_player_dataset(dataset):\n",
    "    \n",
    "    # Convert date to date format\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "\n",
    "    # Strip the round variable to only keep the number\n",
    "    dataset['round'] = dataset['round'].str.split().str[1]\n",
    "\n",
    "    # Replace empty space with missing values\n",
    "    dataset = dataset.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Create a list for object cols\n",
    "    object_cols = ['name', 'date', 'dayofweek', 'round', 'venue', 'result', 'squad',\n",
    "                   'opponent', 'game_started', 'position', 'bench_explain']\n",
    "\n",
    "    # # Except first 3 columns, all columns should be numerical\n",
    "    for col in dataset.columns:\n",
    "        if col not in object_cols:\n",
    "            dataset[col] = dataset[col].astype(float, errors='ignore')\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494c3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_player_dataset(dataset, data_type, directory, team_name):\n",
    "    \n",
    "    create_folder(directory, team_name)\n",
    "\n",
    "    dataset.to_csv(f'{directory}/{team_name}/{data_type}_player_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b422e4",
   "metadata": {},
   "source": [
    "#### Aggregate function for scraping FBref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2cc97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fbref_data(team_name, link, team_table_id, table_ids, data_types, directory):\n",
    "    \n",
    "    print(f'Scraping team data for {team_name}')\n",
    "    \n",
    "    save_team_dataset(clean_team_dataset(create_team_dataset(link, team_table_id)), directory, team_name)\n",
    "    \n",
    "    for table_id, data_type in zip(table_ids, data_types):\n",
    "        \n",
    "        print(f'Scraping squad {data_type} data for {team_name}')\n",
    "        save_squad_dataset(clean_squad_dataset(create_squad_dataset(link, table_id)), data_type, directory, team_name)\n",
    "        \n",
    "        print(f'Scraping player {data_type} data for {team_name}')\n",
    "        save_player_dataset(clean_player_dataset(create_player_dataset(link, table_id)), data_type, directory, team_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e6676",
   "metadata": {},
   "source": [
    "#### Running scraping function for Arsenal F.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a9cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Arsenal'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/18bb7c10/Arsenal-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8913c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Arsenal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Arsenal\n",
      "Scraping player summary data for Arsenal\n",
      "Scraping squad keeping data for Arsenal\n",
      "Scraping player keeping data for Arsenal\n",
      "Scraping squad shooting data for Arsenal\n",
      "Scraping player shooting data for Arsenal\n",
      "Scraping squad passing data for Arsenal\n",
      "Scraping player passing data for Arsenal\n",
      "Scraping squad goal_creation data for Arsenal\n",
      "Scraping player goal_creation data for Arsenal\n",
      "Scraping squad defense data for Arsenal\n",
      "Scraping player defense data for Arsenal\n",
      "Scraping squad possession data for Arsenal\n",
      "Scraping player possession data for Arsenal\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46550f3a",
   "metadata": {},
   "source": [
    "#### Running scraping function for Chelsea F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140627f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Chelsea'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/cff3d9bb/Chelsea-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635d629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Chelsea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Chelsea\n",
      "Scraping player summary data for Chelsea\n",
      "Scraping squad keeping data for Chelsea\n",
      "Scraping player keeping data for Chelsea\n",
      "Scraping squad shooting data for Chelsea\n",
      "Scraping player shooting data for Chelsea\n",
      "Scraping squad passing data for Chelsea\n",
      "Scraping player passing data for Chelsea\n",
      "Scraping squad goal_creation data for Chelsea\n",
      "Scraping player goal_creation data for Chelsea\n",
      "Scraping squad defense data for Chelsea\n",
      "Scraping player defense data for Chelsea\n",
      "Scraping squad possession data for Chelsea\n",
      "Scraping player possession data for Chelsea\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b7b61",
   "metadata": {},
   "source": [
    "#### Running scraping function for Liverpool F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef06899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Liverpool'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/822bd0ba/Liverpool-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a36355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Liverpool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Liverpool\n",
      "Scraping player summary data for Liverpool\n",
      "Scraping squad keeping data for Liverpool\n",
      "Scraping player keeping data for Liverpool\n",
      "Scraping squad shooting data for Liverpool\n",
      "Scraping player shooting data for Liverpool\n",
      "Scraping squad passing data for Liverpool\n",
      "Scraping player passing data for Liverpool\n",
      "Scraping squad goal_creation data for Liverpool\n",
      "Scraping player goal_creation data for Liverpool\n",
      "Scraping squad defense data for Liverpool\n",
      "Scraping player defense data for Liverpool\n",
      "Scraping squad possession data for Liverpool\n",
      "Scraping player possession data for Liverpool\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac0bbe",
   "metadata": {},
   "source": [
    "#### Running scraping function for Man City F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cb4797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Man_City'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/b8fd03ef/Manchester-City-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025d1020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Man_City\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Man_City\n",
      "Scraping player summary data for Man_City\n",
      "Scraping squad keeping data for Man_City\n",
      "Scraping player keeping data for Man_City\n",
      "Scraping squad shooting data for Man_City\n",
      "Scraping player shooting data for Man_City\n",
      "Scraping squad passing data for Man_City\n",
      "Scraping player passing data for Man_City\n",
      "Scraping squad goal_creation data for Man_City\n",
      "Scraping player goal_creation data for Man_City\n",
      "Scraping squad defense data for Man_City\n",
      "Scraping player defense data for Man_City\n",
      "Scraping squad possession data for Man_City\n",
      "Scraping player possession data for Man_City\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd3eb9",
   "metadata": {},
   "source": [
    "#### Running scraping function for West Ham F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d012c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'West_Ham'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/7c21e445/West-Ham-United-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b456c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for West_Ham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for West_Ham\n",
      "Scraping player summary data for West_Ham\n",
      "Scraping squad keeping data for West_Ham\n",
      "Scraping player keeping data for West_Ham\n",
      "Scraping squad shooting data for West_Ham\n",
      "Scraping player shooting data for West_Ham\n",
      "Scraping squad passing data for West_Ham\n",
      "Scraping player passing data for West_Ham\n",
      "Scraping squad goal_creation data for West_Ham\n",
      "Scraping player goal_creation data for West_Ham\n",
      "Scraping squad defense data for West_Ham\n",
      "Scraping player defense data for West_Ham\n",
      "Scraping squad possession data for West_Ham\n",
      "Scraping player possession data for West_Ham\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1982b",
   "metadata": {},
   "source": [
    "#### Running scraping function for Man Utd F.C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe625cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Man_Utd'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/19538871/Manchester-United-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d157811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Man_Utd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Man_Utd\n",
      "Scraping player summary data for Man_Utd\n",
      "Scraping squad keeping data for Man_Utd\n",
      "Scraping player keeping data for Man_Utd\n",
      "Scraping squad shooting data for Man_Utd\n",
      "Scraping player shooting data for Man_Utd\n",
      "Scraping squad passing data for Man_Utd\n",
      "Scraping player passing data for Man_Utd\n",
      "Scraping squad goal_creation data for Man_Utd\n",
      "Scraping player goal_creation data for Man_Utd\n",
      "Scraping squad defense data for Man_Utd\n",
      "Scraping player defense data for Man_Utd\n",
      "Scraping squad possession data for Man_Utd\n",
      "Scraping player possession data for Man_Utd\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea59d4e",
   "metadata": {},
   "source": [
    "#### Running scraping function for Tottenham F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e86a5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Tottenham'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/361ca564/Tottenham-Hotspur-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d22755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Tottenham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Tottenham\n",
      "Scraping player summary data for Tottenham\n",
      "Scraping squad keeping data for Tottenham\n",
      "Scraping player keeping data for Tottenham\n",
      "Scraping squad shooting data for Tottenham\n",
      "Scraping player shooting data for Tottenham\n",
      "Scraping squad passing data for Tottenham\n",
      "Scraping player passing data for Tottenham\n",
      "Scraping squad goal_creation data for Tottenham\n",
      "Scraping player goal_creation data for Tottenham\n",
      "Scraping squad defense data for Tottenham\n",
      "Scraping player defense data for Tottenham\n",
      "Scraping squad possession data for Tottenham\n",
      "Scraping player possession data for Tottenham\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f0bd6",
   "metadata": {},
   "source": [
    "#### Running scraping function for Leicester F.C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5f2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "table_ids = ['stats_standard_11160', 'stats_keeper_adv_11160', 'stats_shooting_11160', 'stats_passing_11160',\n",
    "            'stats_gca_11160', 'stats_defense_11160', 'stats_possession_11160']\n",
    "\n",
    "data_types = ['summary', 'keeping', 'shooting', 'passing', 'goal_creation', 'defense', 'possession']\n",
    "\n",
    "team_name = 'Leicester'\n",
    "team_table_id = 'matchlogs_for'\n",
    "link = 'https://fbref.com/en/squads/a2d435b3/Leicester-City-Stats'\n",
    "directory = '../../data/input/scraped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9a6c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping team data for Leicester\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassansaad/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping squad summary data for Leicester\n",
      "Scraping player summary data for Leicester\n",
      "Scraping squad keeping data for Leicester\n",
      "Scraping player keeping data for Leicester\n",
      "Scraping squad shooting data for Leicester\n",
      "Scraping player shooting data for Leicester\n",
      "Scraping squad passing data for Leicester\n",
      "Scraping player passing data for Leicester\n",
      "Scraping squad goal_creation data for Leicester\n",
      "Scraping player goal_creation data for Leicester\n",
      "Scraping squad defense data for Leicester\n",
      "Scraping player defense data for Leicester\n",
      "Scraping squad possession data for Leicester\n",
      "Scraping player possession data for Leicester\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "scrape_fbref_data(team_name = team_name, link = link, team_table_id = team_table_id,\n",
    "                  table_ids = table_ids, data_types = data_types, directory = directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ae040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
